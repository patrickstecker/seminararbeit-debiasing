# Seminararbeit Debiasing in Machine Learning
Die Voreingenommenheit der Menschen ist ein statisches Problem in der Gesellschaft. Aus der Voreingenommenheit folgt Diskriminierung, und durch Diskriminierung entstehen erhebliche Folgen für die Betroffenen. Dieses Problem ist tief verankert in der Menschheit und es sorgt dafür, dass viele Gruppen von Personen teilweise erheblich benachteiligt werden.  
Künstliche Intelligenzen werden heutzutage in vielen Bereich für kritische Entscheidungen eingesetzt. Durch fehlerhafte Daten oder falsches Training kommt es oft dazu, dass Künstliche Intelligenzen dieses diskriminierende Verhalten der Menschen adaptieren. Das folgt zum Beispiel dazu, dass Gruppen von Personen in Bewerbungsverfahren unberechtigt ausgeschlossen oder bei Kreditvergaben benachteiligt werden.  
Das Ziel des Einsatzes von Künstlichen Intelligenzen in Entscheidungen sollte jedoch die absolute Objektivität sein. Entscheidungen sollten immer fair und nachvollziehbar sein.  
Um dieses Ziel zu erreichen, müssen Verzerrungen in Daten und Modellen erkannt und behoben werden. Durch gegebene Metriken können Daten und Modelle nach Verzerrungen analysiert werden, und durch die vorgestellten Debiasing-Algorithmen können diese Verzerrungen dann anschließend behoben werden. Eine erklärte Implementierung eines Sampling-Algorithmus soll für die Transparenz der Debiasing Algorithmen sorgen. 

Autoren: Daniel Kremsreiter & Patrick Stecker
Copyright 2021
